# Dashboard de Scraping en Tiempo Real

## 1. DescripciÃ³n general

`grafico.py` es un dashboard interactivo desarrollado con FastAPI y Chart.js que permite monitorear el progreso del scraping en tiempo real mediante WebSocket.

**CaracterÃ­sticas principales:**
- VisualizaciÃ³n grÃ¡fica del progreso en tiempo real
- ActualizaciÃ³n automÃ¡tica cada segundo vÃ­a WebSocket
- GrÃ¡fico histÃ³rico de artÃ­culos scrapeados
- MÃ©tricas en vivo: velocidad, errores, progreso del crawler
- Interfaz responsive y moderna

---

## 2. Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         WebSocket          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                 â”‚
â”‚   Dashboard     â”‚    ActualizaciÃ³n cada 1s   â”‚  grafico.py     â”‚
â”‚  (Navegador)    â”‚                            â”‚  (FastAPI)      â”‚
â”‚                 â”‚                            â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
                                                        â”‚ Lee cada 1s
                                                        â”‚
                                                        â–¼
                                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                               â”‚  metrics/           â”‚
                                               â”‚  â”œâ”€ crawler_progressâ”‚
                                               â”‚  â”œâ”€ scraper_progressâ”‚
                                               â”‚  â””â”€ scraper_metrics â”‚
                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Flujo de datos:**
1. Dashboard establece conexiÃ³n WebSocket con el servidor
2. Servidor lee archivos JSON de mÃ©tricas cada segundo
3. Servidor envÃ­a datos actualizados al navegador
4. Dashboard actualiza grÃ¡ficos y estadÃ­sticas automÃ¡ticamente

---

## 3. InstalaciÃ³n

### 3.1. Dependencias

Las dependencias ya estÃ¡n incluidas en `requirements.txt`:

```txt
fastapi
uvicorn[standard]
```

No requiere instalaciones adicionales, ya que Chart.js se carga desde CDN.

### 3.2. Verificar instalaciÃ³n

```bash
source .venv/bin/activate
pip list | grep fastapi
```

---

## 4. EjecuciÃ³n

### 4.1. Iniciar el dashboard

**MÃ©todo 1: EjecuciÃ³n directa**

```bash
python grafico.py
```

**MÃ©todo 2: Con uvicorn (producciÃ³n)**

```bash
uvicorn grafico:app --host 0.0.0.0 --port 8001 --reload
```

### 4.2. Acceder al dashboard

Abrir en el navegador:
- **Local:** http://localhost:8001
- **Red local:** http://[IP_DEL_SERVIDOR]:8001

El dashboard se abre automÃ¡ticamente en el navegador por defecto.

---

## 5. Interfaz y componentes

### 5.1. Barra de estado

Muestra el estado de la conexiÃ³n WebSocket:
- ğŸŸ¢ **Conectado** - Recibiendo actualizaciones en tiempo real
- ğŸ”´ **Desconectado** - Sin conexiÃ³n con el servidor

### 5.2. Tarjetas de estadÃ­sticas

**Sitio Actual**
- Medio siendo scrapeado (BioBio Chile / La Tercera)
- Estado actual del proceso

**URLs Encontradas**
- Total de URLs descubiertas por el crawler
- Muestra "Por el crawler" como subtÃ­tulo

**ArtÃ­culos Exitosos**
- NÃºmero de artÃ­culos scrapeados correctamente
- SubtÃ­tulo: "Scrapeados correctamente"

**Errores**
- Cantidad de fallos en el scraping
- SubtÃ­tulo: "Fallos en scraping"

**Velocidad**
- ArtÃ­culos procesados por minuto
- SubtÃ­tulo: "artÃ­culos/min"

### 5.3. Progreso del Crawler

Barra de progreso visual que muestra:
- Porcentaje de categorÃ­as procesadas
- Estado: "Crawler en proceso..." o "Crawler completado"
- CategorÃ­as procesadas de total (Ej: "26 de 78 categorÃ­as procesadas")

### 5.4. GrÃ¡fico de progreso

GrÃ¡fico de lÃ­neas en tiempo real con:
- **LÃ­nea verde:** ArtÃ­culos exitosos (Ã¡rea rellena)
- **LÃ­nea roja:** Errores
- **Eje X:** Timestamps con formato HH:MM:SS
- **Eje Y:** Cantidad de artÃ­culos

**CaracterÃ­sticas:**
- Se actualiza automÃ¡ticamente cada segundo
- Muestra Ãºltimos 100 puntos de datos
- Animaciones suaves
- Legends interactivas (click para ocultar/mostrar)

---

## 6. Archivos de mÃ©tricas leÃ­dos

El dashboard consume los siguientes archivos JSON:

### 6.1. `crawler_progress.json`

Progreso del crawler en tiempo real.

```json
{
  "sitio": "biobiochile",
  "status": "in_progress",
  "total_categorias": 78,
  "categorias_procesadas": 26,
  "porcentaje": 33.3,
  "urls_encontradas": 450
}
```

### 6.2. `scraper_progress.json`

Progreso de los scrapers por medio (estructura per-medio).

```json
{
  "biobiochile": {
    "total_articulos_exitosos": 268,
    "total_articulos_fallidos": 0,
    "duracion_promedio_ms": 989.85,
    "articulos_por_minuto": 65.24,
    "ultima_actualizacion": "2025-12-12 15:12:39",
    "start_time": "2025-12-12 15:08:33"
  }
}
```

### 6.3. `scraper_metrics.json`

MÃ©tricas finales generadas por el logger al terminar.

```json
{
  "biobiochile": {
    "total_logs": 450,
    "articulos_exitosos": 450,
    "articulos_fallidos": 0,
    "fecha_inicio": "Jueves 12 diciembre de 2025",
    "fecha_termino": "Jueves 12 diciembre de 2025"
  }
}
```

---

## 7. ConfiguraciÃ³n

### 7.1. Puerto del servidor

Por defecto usa el puerto **8001** para no conflictuar con la API principal (puerto 8000).

**Cambiar puerto:**

```python
# En grafico.py, lÃ­nea final
uvicorn.run(app, host="0.0.0.0", port=8001)  # Cambiar 8001
```

### 7.2. Intervalo de actualizaciÃ³n

Por defecto actualiza cada **1 segundo**.

**Cambiar intervalo:**

```python
# En grafico.py, funciÃ³n websocket_endpoint
await asyncio.sleep(1)  # Cambiar a 0.5 para actualizar cada 500ms
```

### 7.3. File locking en lectura

El dashboard usa file locking con `fcntl.LOCK_SH` (shared lock) para leer archivos de forma segura mientras los scrapers escriben.

Ver [api_metricas/routers/metrics_router.py](../api_metricas/routers/metrics_router.py) para la implementaciÃ³n.

---

## 8. Uso conjunto con la API

### Escenario tÃ­pico:

1. **Terminal 1:** Iniciar API de mÃ©tricas
   ```bash
   uvicorn api_metricas.main:app --host 0.0.0.0 --port 8000 --reload
   ```

2. **Terminal 2:** Iniciar dashboard
   ```bash
   python grafico.py
   ```

3. **Terminal 3:** Iniciar scraping via API
   ```bash
   curl -X POST http://localhost:8000/scheduler/start \
     -H "Content-Type: application/json" \
     -d '{"medio": "biobiochile", "num_scrapers": 4}'
   ```

4. **Navegador:** Ver progreso en tiempo real
   - Dashboard: http://localhost:8001
   - API docs: http://localhost:8000/docs

---

## 9. SoluciÃ³n de problemas

### 9.1. Dashboard muestra "Desconectado"

**Causa:** El servidor FastAPI de grafico.py no estÃ¡ corriendo.

**SoluciÃ³n:**
```bash
python grafico.py
```

### 9.2. No se actualizan los datos

**Causa:** Los archivos JSON no existen o estÃ¡n vacÃ­os.

**SoluciÃ³n:**
1. Verificar que el scraping estÃ© corriendo
2. Revisar que existan los archivos en `metrics/`
3. Verificar permisos de lectura

```bash
ls -la metrics/
cat metrics/scraper_progress.json
```

### 9.3. Error de puerto ocupado

**Causa:** El puerto 8001 ya estÃ¡ en uso.

**SoluciÃ³n:**
```bash
# Ver quÃ© proceso usa el puerto
lsof -i :8001

# Matar el proceso
kill -9 [PID]

# O cambiar el puerto en grafico.py
```

### 9.4. GrÃ¡fico no se dibuja

**Causa:** Chart.js no cargÃ³ desde el CDN.

**SoluciÃ³n:**
1. Verificar conexiÃ³n a internet
2. Abrir consola del navegador (F12) para ver errores
3. Recargar la pÃ¡gina (Ctrl+R)

---

## 10. CaracterÃ­sticas avanzadas

### 10.1. DetecciÃ³n de medio actual

El dashboard detecta automÃ¡ticamente el medio que se estÃ¡ scrapeando:

```javascript
// Prioridad:
// 1. Desde crawler_progress.json (field "sitio")
// 2. Desde scraper_progress.json (primera clave disponible)
const medioActivo = data.progress?.sitio || 
                    Object.keys(data.scraper || {})[0] || 
                    'N/A';
```

### 10.2. Manejo de archivos corruptos

Incluye try-catch para JSON invÃ¡lido durante escritura simultÃ¡nea:

```python
try:
    with open(scraper_progress_path, "r") as f:
        content = f.read()
        if content.strip():
            data["scraper"] = json.loads(content)
except (json.JSONDecodeError, IOError):
    pass  # Skip si el archivo estÃ¡ siendo escrito
```

### 10.3. Animaciones suaves

- Transiciones CSS para cambios de valores
- Chart.js con animaciÃ³n activada
- Pulse animation para indicadores en tiempo real

---

## 11. Resumen rÃ¡pido

| AcciÃ³n | Comando |
|--------|---------|
| Iniciar dashboard | `python grafico.py` |
| URL del dashboard | http://localhost:8001 |
| Cambiar puerto | Editar lÃ­nea final de `grafico.py` |
| Ver logs del servidor | Terminal donde se ejecutÃ³ `python grafico.py` |
| Detener dashboard | `Ctrl+C` en la terminal |

### Checklist antes de usar el dashboard

- âœ… API de mÃ©tricas corriendo en puerto 8000
- âœ… Scraping iniciado (via API o manualmente)
- âœ… Archivos en `metrics/` siendo actualizados
- âœ… Dashboard corriendo en puerto 8001
- âœ… Navegador abierto en http://localhost:8001

---

## 12. TecnologÃ­as utilizadas

- **Backend:** FastAPI + WebSocket
- **Frontend:** HTML5 + JavaScript vanilla
- **GrÃ¡ficos:** Chart.js 4.4.0
- **Estilos:** CSS3 con gradientes y animaciones
- **ComunicaciÃ³n:** WebSocket para updates en tiempo real
- **File I/O:** Python pathlib + json

